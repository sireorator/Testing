{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a linear classifier, so you’ll use a linear function 𝑓(𝐱) = 𝑏₀ + 𝑏₁𝑥₁ + ⋯ + 𝑏ᵣ𝑥ᵣ, also called the logit. The variables 𝑏₀, 𝑏₁, …, 𝑏ᵣ are the estimators of the regression coefficients, which are also called the predicted weights or just coefficients.\n",
    "\n",
    "The logistic regression function 𝑝(𝐱) is the sigmoid function of 𝑓(𝐱): 𝑝(𝐱) = 1 / (1 + exp(−𝑓(𝐱)). As such, it’s often close to either 0 or 1. The function 𝑝(𝐱) is often interpreted as the predicted probability that the output for a given 𝐱 is equal to 1. Therefore, 1 − 𝑝(𝑥) is the probability that the output is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output should be NumPy arrays (instances of the class numpy.ndarray) or similar objects. numpy.arange() creates an array of consecutive, equally-spaced values within a given range. For more information on this function, check the official documentation or NumPy arange(): How to Use np.arange().\n",
    "\n",
    "The array x is required to be two-dimensional. It should have one column for each input, and the number of rows should be equal to the number of observations. To make x two-dimensional, you apply .reshape() with the arguments -1 to get as many rows as needed and 1 to get one column. For more information on .reshape(), you can check out the official documentation. Here’s how x and y look now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0, tol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statement creates an instance of LogisticRegression and binds its references to the variable model. LogisticRegression has several optional parameters that define the behavior of the model and approach:\n",
    "\n",
    "- penalty is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
    "\n",
    "- dual is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).\n",
    "\n",
    "\n",
    "- tol is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n",
    "\n",
    "\n",
    "- C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
    "\n",
    "\n",
    "- fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept 𝑏₀ (when True) or consider it equal to zero (when False).\n",
    "\n",
    "\n",
    "- intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept 𝑏₀.\n",
    "\n",
    "\n",
    "- class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
    "\n",
    "\n",
    "- random_state is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n",
    "\n",
    "\n",
    "- solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "\n",
    "\n",
    "- max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n",
    "\n",
    "\n",
    "- multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
    "\n",
    "\n",
    "- verbose is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.\n",
    "\n",
    "\n",
    "- warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n",
    "\n",
    "\n",
    "- n_jobs is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n",
    "\n",
    "\n",
    "- l1_ratio is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization.\n",
    "\n",
    "You should carefully match the solver and regularization method for several reasons:\n",
    "\n",
    "\n",
    "- 'liblinear' solver doesn’t work without regularization.\n",
    "\n",
    "- 'newton-cg', 'sag', 'saga', and 'lbfgs' don’t support L1 regularization.\n",
    "\n",
    "- 'saga' is the only solver that supports elastic-net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can quickly get the attributes of your model. For example, the attribute .classes_ represents the array of distinct values that y takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of binary classification, and y can be 0 or 1, as indicated above.\n",
    "\n",
    "You can also get the value of the slope 𝑏₁ and the intercept 𝑏₀ of the linear function 𝑓 like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.04608067])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51491375]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, 𝑏₀ is given inside a one-dimensional array, while 𝑏₁ is inside a two-dimensional array. You use the attributes .intercept_ and .coef_ to get these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74002157, 0.25997843],\n",
       "       [0.62975524, 0.37024476],\n",
       "       [0.5040632 , 0.4959368 ],\n",
       "       [0.37785549, 0.62214451],\n",
       "       [0.26628093, 0.73371907],\n",
       "       [0.17821501, 0.82178499],\n",
       "       [0.11472079, 0.88527921],\n",
       "       [0.07186982, 0.92813018],\n",
       "       [0.04422513, 0.95577487],\n",
       "       [0.02690569, 0.97309431]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix above, each row corresponds to a single observation. The first column is the probability of the predicted output being zero, that is 1 - 𝑝(𝑥). The second column is the probability that the output is one, or 𝑝(𝑥).\n",
    "\n",
    "You can get the actual predictions, based on the probability matrix and the values of 𝑝(𝑥), with .predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: word unexpected (expecting \")\")\r\n"
     ]
    }
   ],
   "source": [
    "![dataset](data/05/LinearRegression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained matrix shows the following:\n",
    "\n",
    "- Three true negative predictions: The first three observations are zeros predicted correctly.\n",
    "- No false negative predictions: These are the ones wrongly predicted as zeros.\n",
    "- One false positive prediction: The fourth observation is a zero that was wrongly predicted as one.\n",
    "- Six true positive predictions: The last six observations are ones predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, model.predict(x))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.51335372])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.12066084]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97106534, 0.02893466],\n",
       "       [0.9162684 , 0.0837316 ],\n",
       "       [0.7810904 , 0.2189096 ],\n",
       "       [0.53777071, 0.46222929],\n",
       "       [0.27502212, 0.72497788],\n",
       "       [0.11007743, 0.88992257],\n",
       "       [0.03876835, 0.96123165],\n",
       "       [0.01298011, 0.98701989],\n",
       "       [0.0042697 , 0.9957303 ],\n",
       "       [0.00139621, 0.99860379]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
