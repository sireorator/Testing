{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a linear classifier, so you‚Äôll use a linear function ùëì(ùê±) = ùëè‚ÇÄ + ùëè‚ÇÅùë•‚ÇÅ + ‚ãØ + ùëè·µ£ùë•·µ£, also called the logit. The variables ùëè‚ÇÄ, ùëè‚ÇÅ, ‚Ä¶, ùëè·µ£ are the estimators of the regression coefficients, which are also called the predicted weights or just coefficients.\n",
    "\n",
    "The logistic regression function ùëù(ùê±) is the sigmoid function of ùëì(ùê±): ùëù(ùê±) = 1 / (1 + exp(‚àíùëì(ùê±)). As such, it‚Äôs often close to either 0 or 1. The function ùëù(ùê±) is often interpreted as the predicted probability that the output for a given ùê± is equal to 1. Therefore, 1 ‚àí ùëù(ùë•) is the probability that the output is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output should be NumPy arrays (instances of the class numpy.ndarray) or similar objects. numpy.arange() creates an array of consecutive, equally-spaced values within a given range. For more information on this function, check the official documentation or NumPy arange(): How to Use np.arange().\n",
    "\n",
    "The array x is required to be two-dimensional. It should have one column for each input, and the number of rows should be equal to the number of observations. To make x two-dimensional, you apply .reshape() with the arguments -1 to get as many rows as needed and 1 to get one column. For more information on .reshape(), you can check out the official documentation. Here‚Äôs how x and y look now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0, tol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statement creates an instance of LogisticRegression and binds its references to the variable model. LogisticRegression has several optional parameters that define the behavior of the model and approach:\n",
    "\n",
    "- penalty is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
    "\n",
    "- dual is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).\n",
    "\n",
    "\n",
    "- tol is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n",
    "\n",
    "\n",
    "- C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
    "\n",
    "\n",
    "- fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept ùëè‚ÇÄ (when True) or consider it equal to zero (when False).\n",
    "\n",
    "\n",
    "- intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept ùëè‚ÇÄ.\n",
    "\n",
    "\n",
    "- class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
    "\n",
    "\n",
    "- random_state is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n",
    "\n",
    "\n",
    "- solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "\n",
    "\n",
    "- max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n",
    "\n",
    "\n",
    "- multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
    "\n",
    "\n",
    "- verbose is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.\n",
    "\n",
    "\n",
    "- warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n",
    "\n",
    "\n",
    "- n_jobs is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n",
    "\n",
    "\n",
    "- l1_ratio is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization.\n",
    "\n",
    "You should carefully match the solver and regularization method for several reasons:\n",
    "\n",
    "\n",
    "- 'liblinear' solver doesn‚Äôt work without regularization.\n",
    "\n",
    "- 'newton-cg', 'sag', 'saga', and 'lbfgs' don‚Äôt support L1 regularization.\n",
    "\n",
    "- 'saga' is the only solver that supports elastic-net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can quickly get the attributes of your model. For example, the attribute .classes_ represents the array of distinct values that y takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of binary classification, and y can be 0 or 1, as indicated above.\n",
    "\n",
    "You can also get the value of the slope ùëè‚ÇÅ and the intercept ùëè‚ÇÄ of the linear function ùëì like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.04608067])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51491375]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, ùëè‚ÇÄ is given inside a one-dimensional array, while ùëè‚ÇÅ is inside a two-dimensional array. You use the attributes .intercept_ and .coef_ to get these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74002157, 0.25997843],\n",
       "       [0.62975524, 0.37024476],\n",
       "       [0.5040632 , 0.4959368 ],\n",
       "       [0.37785549, 0.62214451],\n",
       "       [0.26628093, 0.73371907],\n",
       "       [0.17821501, 0.82178499],\n",
       "       [0.11472079, 0.88527921],\n",
       "       [0.07186982, 0.92813018],\n",
       "       [0.04422513, 0.95577487],\n",
       "       [0.02690569, 0.97309431]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix above, each row corresponds to a single observation. The first column is the probability of the predicted output being zero, that is 1 - ùëù(ùë•). The second column is the probability that the output is one, or ùëù(ùë•).\n",
    "\n",
    "You can get the actual predictions, based on the probability matrix and the values of ùëù(ùë•), with .predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: word unexpected (expecting \")\")\r\n"
     ]
    }
   ],
   "source": [
    "![dataset](data/05/LinearRegression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained matrix shows the following:\n",
    "\n",
    "- Three true negative predictions: The first three observations are zeros predicted correctly.\n",
    "- No false negative predictions: These are the ones wrongly predicted as zeros.\n",
    "- One false positive prediction: The fourth observation is a zero that was wrongly predicted as one.\n",
    "- Six true positive predictions: The last six observations are ones predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, model.predict(x))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.51335372])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.12066084]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97106534, 0.02893466],\n",
       "       [0.9162684 , 0.0837316 ],\n",
       "       [0.7810904 , 0.2189096 ],\n",
       "       [0.53777071, 0.46222929],\n",
       "       [0.27502212, 0.72497788],\n",
       "       [0.11007743, 0.88992257],\n",
       "       [0.03876835, 0.96123165],\n",
       "       [0.01298011, 0.98701989],\n",
       "       [0.0042697 , 0.9957303 ],\n",
       "       [0.00139621, 0.99860379]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
